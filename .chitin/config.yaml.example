# Example configuration with Chitin sidecar
llm:
  provider: ollama
  model: llama3
  max_tokens: 8192

mcp_servers: []

escalation:
  handler: auto_deny
  timeout_seconds: 0

chitin:
  sidecar_url: "http://localhost:8080"
